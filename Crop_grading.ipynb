{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vanshkumar16/ml_model/blob/main/Crop_grading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfbzOOyOEfXU",
        "outputId": "e53b5cfa-ccff-46af-9a65-e097ee322ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kamal01/top-agriculture-crop-disease?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.33G/4.33G [01:23<00:00, 55.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kamal01/top-agriculture-crop-disease\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_contents = os.listdir('/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1')\n",
        "print(\"Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1\")\n",
        "for item in dataset_contents:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c_ZfYJrE3WO",
        "outputId": "b5af38bd-ad57-47d8-b347-3fd7bc97aa1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1\n",
            "Crop Diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "try:\n",
        "    downloaded_root_contents = os.listdir('/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1')\n",
        "    print(\"Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1\")\n",
        "    for item in downloaded_root_contents:\n",
        "      print(item)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Directory not found at '/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1'\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTuTqzeAE_ul",
        "outputId": "25ac0b18-ea6c-48f3-8328-47ee4b4cfd75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1\n",
            "Crop Diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11acbfd3",
        "outputId": "383ce086-7739-49b3-b3b4-f53ec88573af"
      },
      "source": [
        "import os\n",
        "\n",
        "dataset_root_path = '/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1'\n",
        "dataset_subdir = os.path.join(dataset_root_path, 'Dataset')\n",
        "\n",
        "print(f\"Contents of {dataset_subdir}:\")\n",
        "try:\n",
        "    for item in os.listdir(dataset_subdir):\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory not found at '{dataset_subdir}'\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1/Dataset:\n",
            "Error: Directory not found at '/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1/Dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052bac2b",
        "outputId": "138cd935-b50c-4967-8fcd-fe2336fbf55e"
      },
      "source": [
        "import os\n",
        "\n",
        "print(f\"Contents of {dataset_root_path}:\")\n",
        "try:\n",
        "    for item in os.listdir(dataset_root_path):\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory not found at '{dataset_root_path}'\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1:\n",
            "Crop Diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n"
      ],
      "metadata": {
        "id": "umIa1eVhFHgt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "y72fSoI3FXBN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 38\n",
        "EPOCHS = 10\n",
        "DATASET_ROOT = '/root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1/Crop Diseases/'"
      ],
      "metadata": {
        "id": "TMx48yRjFgkm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NORM_MEAN = [0.485, 0.456, 0.406]\n",
        "NORM_STD = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "id": "Q6jtLsO9FuX1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms for training (includes augmentation)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)), # Resize all images\n",
        "    transforms.RandomHorizontalFlip(),         # Data Augmentation\n",
        "    transforms.RandomRotation(15),             # Data Augmentation\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # Data Augmentation\n",
        "    transforms.ToTensor(),                     # Convert PIL image to Tensor (C, H, W) and normalize to [0, 1]\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)  # Normalize to [-1, 1] range\n",
        "])\n",
        "\n",
        "# Transforms for testing and prediction (no augmentation)\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)), # Resize all images\n",
        "    transforms.ToTensor(),                     # Convert PIL image to Tensor\n",
        "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
        "])"
      ],
      "metadata": {
        "id": "090kpVdXF8Ol"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataloading and DataLoader\n",
        "from torch.utils.data import random_split # Import random_split\n",
        "\n",
        "try:\n",
        "    print(\"\\nAttempting to load data using PyTorch ImageFolder...\")\n",
        "    full_dataset = datasets.ImageFolder(\n",
        "        root=DATASET_ROOT,\n",
        "        transform=train_transforms # Use train_transforms for the full dataset before splitting\n",
        "    )\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "\n",
        "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "    inferred_class_names = [k.replace('_', ' ').title() for k in full_dataset.classes]\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"Successfully found {len(inferred_class_names)} classes.\")\n",
        "    print(f\"Inferred Class Names (Sample): {inferred_class_names[:5]}...\")\n",
        "    print(f\"Training set size: {len(train_dataset)}\")\n",
        "    print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[ERROR] Data Loading Failed: {e}\")\n",
        "    print(f\"Please ensure the dataset is downloaded and extracted into a folder named '{DATASET_ROOT}' with its class subdirectories.\")\n",
        "    inferred_class_names = [f\"Class {i+1}\" for i in range(NUM_CLASSES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDIo4QQjGKXw",
        "outputId": "851ccc64-b84e-44f9-df0b-4a720ae66077"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to load data using PyTorch ImageFolder...\n",
            "Successfully found 17 classes.\n",
            "Inferred Class Names (Sample): ['Corn   Common Rust', 'Corn   Gray Leaf Spot', 'Corn   Healthy', 'Corn   Northern Leaf Blight', 'Potato   Early Blight']...\n",
            "Training set size: 10659\n",
            "Test set size: 2665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model Architectures\n",
        "class CropClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CropClassifier, self).__init__()\n",
        "        # Input (RGB), 128x128\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            # Layer 1: 3 -> 32 filters\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), #  64x64\n",
        "\n",
        "            # Layer 2: 32 -> 64 filters\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), #  32x32\n",
        "\n",
        "            # Layer 3: 64 -> 64 filters\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  #  16x16\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64 * 16 * 16, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # x shape: (Batch_Size, 3, 128, 128)\n",
        "        x = self.conv_layer(x)\n",
        "        # x shape: (Batch_Size, 64, 16, 16)\n",
        "        x = x.reshape(x.size(0), -1) # Flatten for linear layers\n",
        "        # x shape: (Batch_Size, 16384)\n",
        "        x = self.fc_layer(x)\n",
        "        # x shape: (Batch_Size, 38) -> raw logits\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "90MHvOGAHRIO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CropClassifier(NUM_CLASSES).to(DEVICE)\n",
        "print(\"\\n--- Model Architecture ---\")\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_jT-kloJ0y3",
        "outputId": "b5cb1d19-8d9e-4020-a6eb-8d06a1a7d3cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Architecture ---\n",
            "CropClassifier(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=16384, out_features=256, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=256, out_features=38, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=EPOCHS):\n",
        "    print(\"\\n--- Model Training\")\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad() #gradients\n",
        "            outputs = model(inputs) #Forward\n",
        "            loss = criterion(outputs, labels); #Loss\n",
        "            loss.backward() #Backward\n",
        "            optimizer.step() #Optimizer\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    print(\"\\n--- Model Evaluation\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)#Max output\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy on test images: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "tRDw7iyLJ6sW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, locals().get('train_loader'), criterion, optimizer)\n",
        "evaluate_model(model, locals().get('test_loader'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyempu7_NXN2",
        "outputId": "b484e5b7-9e7d-4a0f-8a25-cb3880cba6c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training\n",
            "Epoch 1/10, Loss: 0.4482\n",
            "Epoch 2/10, Loss: 0.3973\n",
            "Epoch 3/10, Loss: 0.3523\n",
            "Epoch 4/10, Loss: 0.3318\n",
            "Epoch 5/10, Loss: 0.3106\n",
            "Epoch 6/10, Loss: 0.3119\n",
            "Epoch 7/10, Loss: 0.2852\n",
            "Epoch 8/10, Loss: 0.2926\n",
            "Epoch 9/10, Loss: 0.2727\n",
            "Epoch 10/10, Loss: 0.2554\n",
            "\n",
            "--- Model Evaluation\n",
            "Accuracy on test images: 88.59%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.59287054409006"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Function\n",
        "\n",
        "def predict_image(image_path: str) -> str:\n",
        "    model.eval()\n",
        "\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = test_transforms(img)\n",
        "        img_tensor = img_tensor.unsqueeze(0)\n",
        "        img_tensor = img_tensor.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(img_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1);\n",
        "        confidence, predicted_index_tensor = torch.max(probabilities, 1)\n",
        "        predicted_index = predicted_index_tensor.item()\n",
        "        predicted_class = inferred_class_names[predicted_index]\n",
        "        confidence_percent = confidence.item() * 100\n",
        "\n",
        "        return f\"Predicted Condition: {predicted_class} ({confidence_percent:.2f}% Confidence)\"\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        return f\"ERROR: Image file not found at path: {image_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during prediction: {e}\""
      ],
      "metadata": {
        "id": "bObmJBYfNYTe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Demonstration of Prediction\n",
        "print(\"\\n--- Prediction Demonstration\")\n",
        "\n",
        "try:\n",
        "\n",
        "    if not full_dataset.classes:\n",
        "        raise ValueError(\"No class names available to pick a sample image. Please ensure full_dataset is loaded correctly.\")\n",
        "\n",
        "    random_class_name_raw = random.choice(full_dataset.classes)\n",
        "    sample_class_dir = os.path.join(DATASET_ROOT, random_class_name_raw)\n",
        "\n",
        "    sample_image_path = None\n",
        "\n",
        "    image_files = [\n",
        "        os.path.join(sample_class_dir, item)\n",
        "        for item in os.listdir(sample_class_dir)\n",
        "        if os.path.isfile(os.path.join(sample_class_dir, item)) and item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))\n",
        "    ]\n",
        "\n",
        "    if image_files:\n",
        "        sample_image_path = random.choice(image_files)\n",
        "        print(f\"Attempting prediction for sample image: {sample_image_path}\")\n",
        "        predicted_result = predict_image(sample_image_path)\n",
        "    else:\n",
        "        predicted_result = f\"ERROR: No image files found in the directory '{sample_class_dir}' for demonstration.\"\n",
        "\n",
        "except Exception as e:\n",
        "    if inferred_class_names:\n",
        "        simulated_index = random.randint(0, len(inferred_class_names) - 1)\n",
        "        simulated_grade = inferred_class_names[simulated_index]\n",
        "        predicted_result = f\"Predicted Condition: {simulated_grade} (Simulated Result: 95.00% Confidence) - Error during actual prediction: {e}\"\n",
        "    else:\n",
        "        predicted_result = f\"An error occurred and no class names were inferred: {e}\"\n",
        "\n",
        "print(f\"\\nResult for a new phone photo: {predicted_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8OHox8COuam",
        "outputId": "cfe69e90-7863-4711-cfb1-088652a9aace"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Prediction Demonstration\n",
            "Attempting prediction for sample image: /root/.cache/kagglehub/datasets/kamal01/top-agriculture-crop-disease/versions/1/Crop Diseases/Rice___Healthy/IMG_20190424_131533.jpg\n",
            "\n",
            "Result for a new phone photo: Predicted Condition: Rice   Healthy (77.54% Confidence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('model12.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model saved as 'model12.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEoRKN47PIMn",
        "outputId": "25b12878-f58c-4d65-8d2c-4b492b6c6abd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'model12.pkl'\n"
          ]
        }
      ]
    }
  ]
}